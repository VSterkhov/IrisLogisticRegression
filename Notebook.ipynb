{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3f83cddd-4a59-4c76-b2f3-c055a0eed984",
   "metadata": {},
   "source": [
    "Инициализация класса логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d682669-96e5-41c6-a841-ef8c30872381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Jul 15 09:02:31 2022\n",
    "\n",
    "@author: vladislav\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def gradients(self, y,y_hat,x):\n",
    "        m = x.shape[0]\n",
    "        dw = (1/m)*np.dot(x.T, (y_hat - y))\n",
    "        db = (1/m)*np.sum((y_hat - y)) \n",
    "        return dw, db\n",
    "    \n",
    "    def loss(self, y, y_hat):\n",
    "        loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
    "        return loss\n",
    "    \n",
    "    def normalize(self, X):\n",
    "        m, n = X.shape\n",
    "        for i in range(n):\n",
    "            X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        return X\n",
    "    \n",
    "    def train(self, X, y, bs, epochs, lr):\n",
    "        m, n = X.shape\n",
    "        self.w = np.zeros((n,1))\n",
    "        self.b = 0\n",
    "        y = y.reshape(bs,1)\n",
    "        x = self.normalize(X)\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i in range((m-1)//bs + 1):\n",
    "                start_i = i*bs\n",
    "                end_i = start_i + bs\n",
    "                xb = X[start_i:end_i]\n",
    "                yb = y[start_i:end_i]\n",
    "                y_hat = self.sigmoid(np.dot(xb, self.w) + self.b)\n",
    "                dw, db = self.gradients(yb, y_hat, xb)\n",
    "                self.w -= lr*dw\n",
    "                self.b -= lr*db\n",
    "            l = self.loss(y, self.sigmoid(np.dot(X, self.w) + self.b))\n",
    "            losses.append(l)\n",
    "        \n",
    "        return self.w, self.b, losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = self.normalize(X)\n",
    "        preds = self.sigmoid(np.dot(X, self.w) + self.b)\n",
    "        \n",
    "        # Empty List to store predictions.\n",
    "        pred_class = []\n",
    "        # if y_hat >= 0.5 --> round up to 1\n",
    "        # if y_hat < 0.5 --> round up to 1\n",
    "        pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "        \n",
    "        return np.array(pred_class)\n",
    "    \n",
    "    def accuracy(self, y, y_hat):\n",
    "        accuracy = np.sum(y == y_hat) / len(y)\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f04e9ef9-ccc0-463b-b4ed-5ca54470c0bb",
   "metadata": {},
   "source": [
    "Загрузка датасета ирисов, обучение модели и вывод точности предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c24f45-7b99-4c77-8d49-8f3475e592bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris\n",
    "from logistic_regression import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "irisBunch = load_iris()\n",
    "data = np.c_[irisBunch.data, irisBunch.target]\n",
    "columns = np.append(irisBunch.feature_names, [\"target\"])\n",
    "irisDF = pd.DataFrame(data, columns=columns)\n",
    "irisDF = irisDF[irisDF['target']!=0]\n",
    "\n",
    "targetData = pd.get_dummies(irisDF.loc[:, irisBunch.feature_names])\n",
    "Y = irisDF['target']\n",
    "Y[Y==1]=0\n",
    "Y[Y==2]=1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(targetData, Y, test_size=0.2)\n",
    "\n",
    "Y_train = Y_train.array\n",
    "Y_test = Y_test.array\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "\n",
    "w, b, losses = logReg.train(X_train, Y_train, X_train.shape[0], 1000, 0.1)\n",
    "\n",
    "\n",
    "pred = logReg.predict(X_test)\n",
    "acc = logReg.accuracy(Y_test, pred)\n",
    "\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a32ab933-2fc2-43e2-bd09-d7eeb96a8046",
   "metadata": {},
   "source": [
    "Точность варьируется от 0.9 до 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
